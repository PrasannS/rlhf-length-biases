{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "392f2224-d5a9-467b-82a6-27d17c4079ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9ec443df-2c8d-4ece-9478-4722eb1e81b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35.9k/35.9k [00:00<00:00, 11.8MB/s]\n",
      "Downloading metadata: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30.4k/30.4k [00:00<00:00, 16.6MB/s]\n",
      "Downloading readme: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16.3k/16.3k [00:00<00:00, 29.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('wikipedia', \"20220301.en\", split='train', streaming=True)\n",
    "shuffled_dataset = dataset.shuffle(seed=42, buffer_size=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "04d8e9d5-8904-41a6-94b8-81617ebdeb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = dataset.take(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f22b4e3b-a1b6-42e7-a913-5192464ea14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selwikidata = list(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62dc52d-42f2-4bd4-9477-ee0bc291c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTDATA = 60000\n",
    "quotesdata = quotesdata['train'].shuffle(seed=0)\n",
    "quotesdata = quotesdata.select(range(TOTDATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "540d5979-6855-4db0-9474-112b880c26a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': \"The rose, however, made us girls somewhat fainthearted, because it really was something we felt mattered, the white bridal dream with the wedding bouquet and the kiss from the man who was to be ours forever. But then Laura said that the lady who had given it to us had gotten divorced only five years later. And since many of our parents were also divorce, if indeed they had ever been married at all, that dream clearly wasn't worth our time.\",\n",
       " 'author': 'Janne Teller',\n",
       " 'category': 'marriage, nothing'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotesdata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "548c0fe1-3b87-4952-9bfb-887619b68c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"EleutherAI/gpt-neo-1.3B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb276ba2-8676-4745-b703-d6ed729cc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(modelname, device_map=0)\n",
    "toker = AutoTokenizer.from_pretrained(modelname, padding_side='left')\n",
    "\n",
    "toker.max_length=512\n",
    "toker.padding_size='left'\n",
    "toker.pad_token = toker.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "05d1aaa6-e246-4af9-9f87-c15cffa3bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_quotes(exs):\n",
    "    inps = []\n",
    "    for e in exs:\n",
    "        inps.append(e['author']+ \": \" + e['quote'])\n",
    "    return inps\n",
    "        \n",
    "def generate_trunc(inputs, trunc, model):\n",
    "    newinps = []\n",
    "    corrgens = []\n",
    "    for inp in inputs: \n",
    "        newinps.append(toker.decode(toker(inp).input_ids[:-(trunc+1)], skip_special_tokens=True))\n",
    "        corrgens.append(toker.decode(toker(inp).input_ids[-(trunc+1):], skip_special_tokens=True))\n",
    "    inps = toker(newinps, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "    newgens = model.generate(**inps, max_new_tokens=trunc+1, do_sample=True, top_p=0.8)\n",
    "    return toker.batch_decode(newgens, skip_special_tokens=True), corrgens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cb136151-773b-4fcc-9e33-bd83a7045daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "procd = proc_quotes(quotesdata.select(range(10)))\n",
    "gtrunc, golds = generate_trunc(procd, 3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "60a094cd-3741-45ec-afcd-bf7139d50fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL: Baris Gencel: At this stage I can see most of the men are still primitive about sexual perception and conception.\n",
      "GOLD:  perception and conception.\n",
      "GEN: Baris Gencel: At this stage I can see most of the men are still primitive about sexual desire and so there\n"
     ]
    }
   ],
   "source": [
    "ind = 2\n",
    "print(\"ORIGINAL: \"+procd[ind])\n",
    "print('GOLD: '+golds[ind])\n",
    "print(\"GEN: \"+gtrunc[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f005b5c-7bd0-481b-96e8-e24a3a257cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
