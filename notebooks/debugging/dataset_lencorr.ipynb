{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec038c24-5f5f-40ff-928c-9ecfef480e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from transformers import AutoTokenizer\n",
    "from rlhfutils.data import preproc_wgpt, preproc_apf, preproc_hh\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256d4d8-ce12-4422-a5c8-9e1b17c935b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a92a1-d969-40f3-964c-8ae18a629242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rlcd = load_dataset(\"csv\", data_files=\"../simulated_data/simulated_preference_data_consolidated_helpful7b.csv\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd02249-64e6-437a-8f32-f8f5e5594b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rlcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c4bea-2e87-444b-bc36-7cc39dc98768",
   "metadata": {},
   "outputs": [],
   "source": [
    "webgpt = load_dataset(\"openai/webgpt_comparisons\", split=\"train\")\n",
    "webgpt = pd.DataFrame([preproc_wgpt(w) for w in webgpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3758cd3-5ffd-447e-8df0-e4b701afa61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = load_dataset(\"lvwerra/stack-exchange-paired\", data_dir=\"data/reward\", split=\"train\")\n",
    "stack = stack.select(range(100000))\n",
    "stack = pd.DataFrame(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4121a181-b163-4ec4-8ae3-a5e588bee934",
   "metadata": {},
   "outputs": [],
   "source": [
    "apfgpt = load_dataset(\"tatsu-lab/alpaca_farm\", 'alpaca_gpt4_preference')['preference']\n",
    "apfhum= load_dataset(\"tatsu-lab/alpaca_farm\", 'alpaca_human_preference')['preference']\n",
    "apfgpt = pd.DataFrame([preproc_apf(w) for w in apfgpt])\n",
    "apfhum = pd.DataFrame([preproc_apf(w) for w in apfhum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d6729-25af-4c5f-8751-43a58160dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_train = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-base\", split=\"train\")\n",
    "hh_train = pd.DataFrame([preproc_hh(w) for w in hh_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1322bd-84cc-4a15-8c95-78034fc62569",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 4\n",
    "print(hh_train['response_k'][ind])\n",
    "print(\"_____\")\n",
    "print(hh_train['response_j'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57512873-23fe-491e-b9ff-b4aa341a41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/sft10k/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4131c-55d7-47ad-900d-3164bf0a8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE I validated that RLCD doesn't have any input formatted stuff\n",
    "def rlcdmakeprefs (inpdf):\n",
    "    allres = []\n",
    "    for row in inpdf:\n",
    "        res = {}\n",
    "        res['question'] = row['instruction']\n",
    "        if row['preference']==1:\n",
    "            res['response_j'] = row['output_1']\n",
    "            res['response_k'] = row['output_2']\n",
    "        else:\n",
    "            res['response_j'] = row['output_2']\n",
    "            res['response_k'] = row['output_1']\n",
    "        allres.append(res)\n",
    "    return pd.DataFrame(allres).dropna().reset_index(drop=True)\n",
    "\n",
    "# take in processed df, given tokenizer, tokenize everything\n",
    "def tokall (pdf): \n",
    "    gtoks = []\n",
    "    btoks = []\n",
    "    for ind, row in pdf.iterrows():\n",
    "        gtoks.append(len(tokenizer(row['response_j']).input_ids))\n",
    "        btoks.append(len(tokenizer(row['response_k']).input_ids))\n",
    "    pdf['gtoks'] = gtoks\n",
    "    pdf['btoks'] = btoks\n",
    "    pdf['diffv'] = pdf['gtoks'] - pdf['btoks']\n",
    "    return pdf\n",
    "\n",
    "def lenbias (indf):\n",
    "    return (indf['gtoks']>indf['btoks']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87090c-a2a1-4c5d-9aee-23a9f23e3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"processing\")\n",
    "rlcproc = rlcdmakeprefs(rlcd)\n",
    "print(\"tokenizing\")\n",
    "rlcproc = tokall(rlcproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fb359-3afb-4a97-b926-30558eee8514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ce24b-fc95-48ae-842b-c45c28252e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlcproc['diffv'] = rlcproc['gtoks']-rlcproc['btoks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede18e6-622b-442d-99d8-3cf64e884538",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rlcproc['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88718152-4640-4abe-b4f2-0a247bff4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgptproc = tokall(webgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364ec92-bddb-479e-b036-8e8b8233cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(list(wgptproc.gtoks)+list(wgptproc.btoks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81c97b-3e44-40c0-9bac-cb63ca841c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baldf(indf):\n",
    "    df = indf.copy()\n",
    "    # Create bins of 10\n",
    "    bins = range(-200, 201, 10)\n",
    "    df['bin'] = pd.cut(df['diffv'], bins=bins)\n",
    "    \n",
    "    # Initialize an empty DataFrame to store balanced data\n",
    "    balanced_df = pd.DataFrame()\n",
    "    \n",
    "    # Get unique bin labels from the DataFrame\n",
    "    unique_bins = df['bin'].dropna().unique()\n",
    "    \n",
    "    # Iterate through each pair of negative and positive bins\n",
    "    for bin_label in unique_bins:\n",
    "        if bin_label.left >= 0:\n",
    "            continue\n",
    "    \n",
    "        # Find the positive counterpart of the current negative bin\n",
    "        positive_bin = pd.Interval(-bin_label.right, -bin_label.left)\n",
    "    \n",
    "        # If the positive counterpart is not in unique_bins, skip this iteration\n",
    "        if positive_bin not in unique_bins:\n",
    "            continue\n",
    "    \n",
    "        # Find the counts for the negative and positive bins\n",
    "        neg_count = df[df['bin'] == bin_label].shape[0]\n",
    "        pos_count = df[df['bin'] == positive_bin].shape[0]\n",
    "    \n",
    "        # Find the minimum count to balance the data\n",
    "        min_count = min(neg_count, pos_count)\n",
    "    \n",
    "        # Randomly sample min_count rows from each bin and append to balanced_df\n",
    "        sampled_neg = df[df['bin'] == bin_label].sample(min_count, random_state=0)\n",
    "        sampled_pos = df[df['bin'] == positive_bin].sample(min_count, random_state=0)\n",
    "    \n",
    "        balanced_df = pd.concat([balanced_df, sampled_neg, sampled_pos])\n",
    "    \n",
    "    # Reset index of the balanced DataFrame\n",
    "    balanced_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Now balanced_df contains the balanced data\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbe8b0-41a9-4eb9-97db-57e0dd15e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "balwgpt = baldf(wgptproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a29377-c3b8-400a-b65a-0c325dc6f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "balrlcd = baldf(rlcproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6facd65-301d-4726-b129-b8bf729d1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(balrlcd.diffv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086aaa69-49e9-4b66-8506-257113bbe3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenbias(wgptproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28890a0c-dc2b-48c0-9878-43df3394405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackproc = tokall(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612e8cd-20e6-4b9c-b415-22d1f1de5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(list(stackproc.gtoks)+list(stackproc.btoks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e9ecb-d46c-4208-b0d6-7217e5a6610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenbias(stackproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b59e1-3e93-47f5-8d17-09c0bde6b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "apfhumbproc = tokall(apfhum)\n",
    "apfgptproc = tokall(apfgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49de53-c380-479c-a1ed-961a865b26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lenbias(apfhumbproc))\n",
    "print(lenbias(apfgptproc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1260771-81fe-46c6-8d86-04050d624bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhproc = tokall(hh_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae169927-f03e-4f37-887a-7cce82a12655",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenbias(hhproc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
