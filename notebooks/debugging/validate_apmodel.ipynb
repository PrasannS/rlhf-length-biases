{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a06a07-ef7d-402b-925c-01860068485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasann/miniconda3/envs/rlenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-04 18:55:46,169] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from alpaca_farm.models import reward_model\n",
    "from alpaca_farm.inference.decode import load_model_and_tokenizer_for_inference \n",
    "from alpaca_farm.inference.score import score_sequences_with_huggingface_given_model\n",
    "import alpaca_farm.data_preprocessor as data_preprocessor\n",
    "from alpaca_farm import utils\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rlhfutils.debug_utils import load_all_dfs, load_rm, progress_rm\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25817245-3938-4a63-94fb-5fe1390c41b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.48s/it]\n",
      "Using /data/users/prasann/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /data/users/prasann/.cache/torch_extensions/py39_cu117/cuda_kernel/build.ninja...\n",
      "Building extension module cuda_kernel...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module cuda_kernel...\n"
     ]
    }
   ],
   "source": [
    "apfrm = load_rm(\"../apf/models/humannew/\", 0)\n",
    "tok, apfrm, kwargs = apfrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a0b3d7-9b49-42f2-9181-6f1d20e958bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_apfarm(row):\n",
    "    qstr = \"\"\n",
    "    if len(row['input'])>0:\n",
    "        qstr = row['instruction']+\"\\n\\nInput: \"+row['input']\n",
    "    else:\n",
    "        qstr = row['instruction']\n",
    "    \n",
    "    return \"Question: \" + qstr + \"\\n\\nAnswer: \" + row['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773c7df3-e42b-4d35-b175-7563d169f670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset alpaca_farm (/home/prasann/.cache/huggingface/datasets/tatsu-lab___alpaca_farm/alpaca_human_preference/1.0.0/79d38dc3f12abd62869e376303b68092e8385769e22f05166fe96a3dac29a57a)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 339.32it/s]\n",
      "Loading cached shuffled indices for dataset at /home/prasann/.cache/huggingface/datasets/tatsu-lab___alpaca_farm/alpaca_human_preference/1.0.0/79d38dc3f12abd62869e376303b68092e8385769e22f05166fe96a3dac29a57a/cache-f4eaec1c5d8e30f0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size  9691\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"tatsu-lab/alpaca_farm\", 'alpaca_human_preference')['preference']\n",
    "print(\"initial size \", len(train_dataset))\n",
    "train_dataset = train_dataset.shuffle(seed=100)\n",
    "eval_dataset = train_dataset.select(range(0,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "507fbc21-31de-45c2-8f68-6c356ce877e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_to_single(ex, choosebest=True):\n",
    "    if (ex['preference']==1)==choosebest:\n",
    "        return {\n",
    "            'instruction': ex['instruction'], \n",
    "            'input': ex['input'],\n",
    "            'output': ex['output_1']\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'instruction': ex['instruction'], \n",
    "            'input': ex['input'],\n",
    "            'output': ex['output_2']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90975a0a-5684-4d15-9830-221152ed3056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/prasann/.cache/huggingface/datasets/tatsu-lab___alpaca_farm/alpaca_human_preference/1.0.0/79d38dc3f12abd62869e376303b68092e8385769e22f05166fe96a3dac29a57a/cache-e3c5187e42089dd6.arrow\n",
      "Loading cached processed dataset at /home/prasann/.cache/huggingface/datasets/tatsu-lab___alpaca_farm/alpaca_human_preference/1.0.0/79d38dc3f12abd62869e376303b68092e8385769e22f05166fe96a3dac29a57a/cache-367e129c7153e56e.arrow\n"
     ]
    }
   ],
   "source": [
    "badmaps = eval_dataset.map(lambda x: pair_to_single(x, False))\n",
    "goodmaps = eval_dataset.map(lambda x: pair_to_single(x, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af03ad5e-b545-44eb-a3fb-d1dc79984444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return_all_scores': True,\n",
       " 'function_to_apply': 'none',\n",
       " 'batch_size': 8,\n",
       " 'truncation': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aedef0fe-0bad-4a5a-8baf-c05154a94340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreouts(rows):\n",
    "    seqs = [adjust_apfarm(r) for r in rows]\n",
    "    print(seqs[0])\n",
    "    scores = progress_rm(seqs, apfrm, kwargs)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a9f0b5-3c58-47b4-a813-ce9f40c447a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Construct a proof of the following theorem:\n",
      "\n",
      "Input: Theorem: The sum of two odd numbers is even.\n",
      "\n",
      "Answer: Let's suppose we have two odd numbers, a and b. Then, a + b will be a sum of two odd numbers, so it will be even. This is because the sum of two odd numbers will always be odd. But if a and b are even, they will give a sum that is mathematically even, which is simply a consequence of them both being even numbers. Thus, the theorem holds and is proven.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                 | 0/32 [00:00<?, ?it/s]/home/prasann/miniconda3/envs/rlenv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      " 31%|█████████████████████████████████████▌                                                                                  | 10/32 [00:29<00:56,  2.57s/it]/home/prasann/miniconda3/envs/rlenv/lib/python3.9/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:57<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "bscos = scoreouts(badmaps)\n",
    "badscos = [b[0]['score'] for b in bscos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dea75e3-211f-42c8-8254-ba318e939f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Construct a proof of the following theorem:\n",
      "\n",
      "Input: Theorem: The sum of two odd numbers is even.\n",
      "\n",
      "Answer: Proof: Let's assume the theorem is true. We can take any two odd numbers and add them together to get a sum. This sum, by definition, is also odd, meaning that the sum of two odd numbers must also be even.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:39<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "gscos = scoreouts(goodmaps)\n",
    "goodscos = [b[0]['score'] for b in gscos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db9a1b90-7fcd-486b-a252-0cc6bf4b0c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([1 if goodscos[i] > badscos[i] else 0 for i in range(len(goodscos))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7da9ec-c866-4ef5-973b-c8b7771e2642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
