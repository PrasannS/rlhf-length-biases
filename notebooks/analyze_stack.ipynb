{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1295c2e3-982a-4ca8-8044-9220beebe5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/prasanns/miniconda3/envs/rlhfenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-23 15:07:00,503] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from rlhfutils.data import load_manual\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "from rlhfutils.rmcode import RewardDataCollatorWithPadding, compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff97036b-f8af-449e-8f62-a0247050dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "toker = AutoTokenizer.from_pretrained(\"../models/stack/sft/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fc09b6-902e-4484-a905-cd7059b7b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOING THROUGH PROCESS FOR stack_english\n",
      "initial size  65895\n",
      "59305\n",
      "eval len\n",
      "6590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|                                                                                                                                              | 0/6590 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3231 > 2048). Running this sequence through the model will result in indexing errors\n",
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOING THROUGH PROCESS FOR stack_diy\n",
      "initial size  22360\n",
      "20124\n",
      "eval len\n",
      "2236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOING THROUGH PROCESS FOR stack_physics\n",
      "initial size  53401\n",
      "48060\n",
      "eval len\n",
      "5341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOING THROUGH PROCESS FOR stack_stats\n",
      "initial size  20776\n",
      "18698\n",
      "eval len\n",
      "2078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOING THROUGH PROCESS FOR stack_softwareengineering\n",
      "initial size  42997\n",
      "38697\n",
      "eval len\n",
      "4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOING THROUGH PROCESS FOR stack_scifi\n",
      "initial size  25693\n",
      "23123\n",
      "eval len\n",
      "2570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    }
   ],
   "source": [
    "# HERE we'll setup code to run stack RMs and measure accuracy overlap across different sets of data\n",
    "# print(listdir(\"../data/categories/\"))\n",
    "def get_toklens(ex):\n",
    "    ex['tj'] = len(toker(ex['response_j']).input_ids)\n",
    "    ex['tk'] = len(toker(ex['response_k']).input_ids)\n",
    "    return ex\n",
    "    \n",
    "# select datasets to examine\n",
    "evals = ['english', 'diy', 'physics', 'stats', 'softwareengineering', 'scifi']\n",
    "# load 'em in\n",
    "dsets = {}\n",
    "for e in evals: \n",
    "    _, ev = load_manual(\"stack_\"+e, \"../data/categories/\")\n",
    "    ev = ev.map(get_toklens)\n",
    "    dsets[e] = ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd313f75-012b-4a3a-a2c0-9e6696dc46a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /scratch/cluster/prasanns/research/rlhf-length-biases/data/categories/english/cache-5b0daf50f9686d10.arrow\n",
      "Loading cached processed dataset at /scratch/cluster/prasanns/research/rlhf-length-biases/data/categories/diy/cache-51bf3df98944fb2e.arrow\n",
      "Loading cached processed dataset at /scratch/cluster/prasanns/research/rlhf-length-biases/data/categories/physics/cache-9ff7d66ac9ba3bbe.arrow\n",
      "Loading cached processed dataset at /scratch/cluster/prasanns/research/rlhf-length-biases/data/categories/stats/cache-56f2af62442f00a8.arrow\n",
      "Loading cached processed dataset at /scratch/cluster/prasanns/research/rlhf-length-biases/data/categories/softwareengineering/cache-e73688aefd31cd5a.arrow\n",
      "Loading cached processed dataset at /scratch/cluster/prasanns/research/rlhf-length-biases/data/categories/scifi/cache-3f78197f66d779c1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english\n",
      "0.6206373292867982\n",
      "diy\n",
      "0.618515205724508\n",
      "physics\n",
      "0.6150533607938589\n",
      "stats\n",
      "0.6448508180943214\n",
      "softwareengineering\n",
      "0.596046511627907\n",
      "scifi\n",
      "0.6762645914396888\n"
     ]
    }
   ],
   "source": [
    "for e in evals: \n",
    "    print(e)\n",
    "    print(len(dsets[e].filter(lambda x: x['tj'] > x['tk']))/len(dsets[e]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ad3167-b1b6-43ce-af6b-37ee018af863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english': Dataset({\n",
       "     features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k', 'magnitude'],\n",
       "     num_rows: 6590\n",
       " }),\n",
       " 'diy': Dataset({\n",
       "     features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k', 'magnitude'],\n",
       "     num_rows: 2236\n",
       " }),\n",
       " 'physics': Dataset({\n",
       "     features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k', 'magnitude'],\n",
       "     num_rows: 5341\n",
       " }),\n",
       " 'stats': Dataset({\n",
       "     features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k', 'magnitude'],\n",
       "     num_rows: 2078\n",
       " }),\n",
       " 'softwareengineering': Dataset({\n",
       "     features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k', 'magnitude'],\n",
       "     num_rows: 4300\n",
       " }),\n",
       " 'scifi': Dataset({\n",
       "     features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k', 'magnitude'],\n",
       "     num_rows: 2570\n",
       " })}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9db556-58fd-415b-878a-dd3e86d81a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for setting up RMs (keep in peft mode to avoid this taking 2 years)\n",
    "ckptbase = \"../checkpoints/stackrms/stack_\"\n",
    "def loadrm(name, bm):\n",
    "    model = PeftModel.from_pretrained(bm, ckptbase+name+\"/_peft_last_checkpoint/\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# get the basemodel ready to go\n",
    "basemodel = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL_NAME, num_labels=1, torch_dtype=torch.bfloat16\n",
    ").to(7)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "rdc = RewardDataCollatorWithPadding(tokenizer=tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "077faafb-2b68-48a0-9e70-7c056b431512",
   "metadata": {},
   "outputs": [],
   "source": [
    "testmod = loadrm(evals[0], basemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff5264dc-4c57-4622-807d-0adbb944bc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3834d477-fcc3-41cc-9baf-ec8584b3dceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23115"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(dsets[l]) for l in dsets.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d358a-b8ac-439d-be73-b3a87e7e1798",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dataset = load_from_disk(\"../data/stackmagnitude/\")['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5b1e0-5a59-4ac2-b2f0-7009336e591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your categories\n",
    "#categories = ['https://math.stackexchange.com', 'https://scifi.stackexchange.com', 'https://spanish.stackexchange.com', 'https://mythology.stackexchange.com', 'https://biology.stackexchange.com']\n",
    "categories = []\n",
    "# Create a dictionary to store datasets for each category\n",
    "#filtered_datasets = {}\n",
    "\n",
    "for category in categories:\n",
    "    filtered_datasets[category] = orig_dataset.filter(lambda x: x['metadata'][1] == category, num_proc=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f510d7-5dac-4f5c-ad71-efceff63f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(sources)\n",
    "\n",
    "# Collect indices for each category\n",
    "category_indices = {category: [] for category in categories}\n",
    "\n",
    "for i, row in tqdm(enumerate(orig_dataset), total=len(orig_dataset)):\n",
    "    category = row['metadata'][1]\n",
    "    if category in category_indices:\n",
    "        category_indices[category].append(i)\n",
    "\n",
    "# Create a dictionary to store datasets for each category\n",
    "filtered_datasets = {}\n",
    "\n",
    "for category, indices in category_indices.items():\n",
    "    filtered_datasets[category] = orig_dataset.select(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87555554-682f-4bb8-b14e-d48c8743464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "categories = list(sources)\n",
    "# Load your big dataset\n",
    "dataset = orig_dataset\n",
    "def collect_indices(start_end):\n",
    "    start, end = start_end\n",
    "    local_indices = {category: [] for category in categories}\n",
    "\n",
    "    for i in tqdm(range(start, end)):\n",
    "        row = dataset[i]\n",
    "        category = row['metadata'][1]\n",
    "        if category in local_indices:\n",
    "            local_indices[category].append(i)\n",
    "    \n",
    "    return local_indices\n",
    "\n",
    "# Create chunks for parallel processing\n",
    "num_cores = cpu_count()\n",
    "chunk_size = len(dataset) // num_cores\n",
    "#chunks = [(i, i+chunk_size) for i in range(0, len(dataset), chunk_size)]\n",
    "chunks = [(i, min(i+chunk_size, len(dataset))) for i in range(0, len(dataset), chunk_size)]\n",
    "\n",
    "# Process chunks in parallel with tqdm progress bar\n",
    "with Pool(num_cores) as p:\n",
    "    results = list(p.imap(collect_indices, chunks))\n",
    "\n",
    "# Combine results from all chunks\n",
    "category_indices = {category: [] for category in categories}\n",
    "for local_indices in results:\n",
    "    for category in categories:\n",
    "        category_indices[category].extend(local_indices[category])\n",
    "\n",
    "# Create datasets for each category\n",
    "filtered_datasets = {}\n",
    "for category, indices in category_indices.items():\n",
    "    filtered_datasets[category] = dataset.select(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1343c-e78c-4293-a801-1280d6a70e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "refilt = {}\n",
    "totdata = 0\n",
    "for f in filtered_datasets.keys():\n",
    "    if len(filtered_datasets[f])>10000 and len(filtered_datasets[f])<100000:\n",
    "        refilt[f.replace(\"https://\", \"\").replace(\".com\", \"\").replace(\".stackexchange\", \"\")] = filtered_datasets[f]\n",
    "        totdata = totdata+len(filtered_datasets[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70570a14-bf9c-42da-b1c1-8d5c2c39d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedsets = ['https://english.stackexchange.com', 'https://workplace.stackexchange.com', 'https://apple.stackexchange.com', 'https://scifi.stackexchange.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4662d-b1b4-4b9f-8811-be5624652261",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in refilt: \n",
    "    refilt[f].save_to_disk(\"../data/\"+f+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3143c7c4-7081-4094-86b3-022192ca159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "refilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175dcf6-09f7-4a78-bbd0-a7c9952beb59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up scripts to train the large RM sets\n",
    "for s in refilt.keys():\n",
    "    temp = \"\"\"\n",
    "    torchrun --nnodes 1  --nproc_per_node 8 --master_port=12335 scripts/train_rm.py \\\\\n",
    "        --model_name=/u/prasanns/research/rlhf-length-biases/models/stack/sft \\\\\n",
    "        --output_dir=checkpoints/stackrms/stack_\"\"\"+s+\"\"\" \\\\\n",
    "        --dataset=\\\"stack_\"\"\"+s+\"\"\"\\\" \\\\\n",
    "        --rand_ratio=0 \\\\\n",
    "        --balance_len=0 \\\\\n",
    "        --num_train_epochs=1\"\"\"\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e3a6e-b8b5-4ef9-a796-e73d6de01b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uchat = load_dataset(\"stingning/ultrachat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173f2eb-2cde-4acd-88e2-c4e3d692ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = set()\n",
    "for s in tqdm(orig_dataset['metadata'][:1000]):\n",
    "    sources.add(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4c37a-e34d-4621-aa5f-32457a9a9634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9bf44-a571-421e-8824-78c8c13f0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(orig_dataset[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ae82d-b4e4-4b43-808a-ce62aeeda770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['metadata'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fef83c-41af-448a-98bf-0451ea4faa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([orig_dataset['metadata'][i][1] for i in range(len(orig_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00c2f3-9318-452a-9c7b-a0a2acf836f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
