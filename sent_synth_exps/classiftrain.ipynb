{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d474f746-1af3-40b4-b6c9-57ce80c6151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb347041-8182-4646-9309-1d8e05143ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/prasann/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.96it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"imdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5da84c-aaf7-40bd-b8a2-23532becd0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 483/483 [00:00<00:00, 50.4kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-03 18:47:31,420] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 268M/268M [00:02<00:00, 113MB/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading (…)okenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 2.58kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 15.7MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 104MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82529140-c859-49fe-baf2-1856d0c5e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                               \r"
     ]
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "    outputs = tokenizer(examples['text'], truncation=True)\n",
    "    return outputs\n",
    "\n",
    "tokenized_ds = ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7bbae7b-5642-4377-9b5e-1fd758118950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a06325cc-82b7-4f16-8b5c-d55f22be095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(num_train_epochs=1,\n",
    "          output_dir=\"distilbert-imdb\",\n",
    "          push_to_hub=False,\n",
    "          per_device_train_batch_size=16,\n",
    "          per_device_eval_batch_size=16,\n",
    "          evaluation_strategy=\"epoch\",\n",
    "          logging_steps=100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7fb2fa1-8b5e-4a07-9520-ac82cd1172fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer,\n",
    "                  data_collator=data_collator,\n",
    "                  args=training_args,\n",
    "                  train_dataset=tokenized_ds[\"train\"],\n",
    "                  eval_dataset=tokenized_ds[\"test\"], \n",
    "                  \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "502caf37-4a11-4ce5-88a9-6d4c77173aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 07:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.205700</td>\n",
       "      <td>0.189076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.1978155451559212, metrics={'train_runtime': 431.6714, 'train_samples_per_second': 57.914, 'train_steps_per_second': 3.621, 'total_flos': 3284752688410752.0, 'train_loss': 0.1978155451559212, 'epoch': 1.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622381d-56d3-4c0d-bc2f-2efa1d2671f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
